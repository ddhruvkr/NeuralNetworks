{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# this is a from scratch implementation of a simple RNN having 2 hidden layers\n",
    "# it reads in any text file, tries it to learn character by character and then generates sentences\n",
    "# the basic code is taken from http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
    "data = open('kafka.txt', 'r').read()\n",
    "chars = list(set(data))\n",
    "totalCharacters = len(data)\n",
    "vocabLen = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'p': 2, 'c': 3, 'z': 4, 'N': 5, 'x': 6, 'I': 7, '\\n': 8, '?': 9, 's': 10, 'S': 11, 'l': 12, 'F': 13, '\"': 14, 'm': 15, 'U': 16, 'k': 17, 'j': 18, 'P': 19, ',': 20, 'T': 21, 'H': 22, 'w': 23, 'y': 24, 'e': 25, 'J': 26, 'C': 27, 'L': 28, 'M': 29, '(': 30, 'r': 31, '!': 32, 'o': 33, \"'\": 34, 'q': 35, 'E': 36, 'O': 37, ' ': 38, 'n': 39, 'W': 40, '-': 41, ':': 42, 'f': 43, 'รง': 44, 'v': 45, 'V': 46, 't': 47, 'u': 48, 'G': 49, 'Y': 50, 'i': 51, 'Q': 52, 'd': 53, 'A': 54, 'D': 55, 'g': 56, 'h': 57, ')': 58, 'B': 59, '.': 60, ';': 61}\n",
      "{0: 'a', 1: 'b', 2: 'p', 3: 'c', 4: 'z', 5: 'N', 6: 'x', 7: 'I', 8: '\\n', 9: '?', 10: 's', 11: 'S', 12: 'l', 13: 'F', 14: '\"', 15: 'm', 16: 'U', 17: 'k', 18: 'j', 19: 'P', 20: ',', 21: 'T', 22: 'H', 23: 'w', 24: 'y', 25: 'e', 26: 'J', 27: 'C', 28: 'L', 29: 'M', 30: '(', 31: 'r', 32: '!', 33: 'o', 34: \"'\", 35: 'q', 36: 'E', 37: 'O', 38: ' ', 39: 'n', 40: 'W', 41: '-', 42: ':', 43: 'f', 44: 'รง', 45: 'v', 46: 'V', 47: 't', 48: 'u', 49: 'G', 50: 'Y', 51: 'i', 52: 'Q', 53: 'd', 54: 'A', 55: 'D', 56: 'g', 57: 'h', 58: ')', 59: 'B', 60: '.', 61: ';'}\n"
     ]
    }
   ],
   "source": [
    "characterToIndex = {ch:i for i,ch in enumerate(chars)}\n",
    "print(characterToIndex)\n",
    "indexToCharacter = {i:ch for i,ch in enumerate(chars)}\n",
    "print(indexToCharacter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#hyperparameters\n",
    "learningRate = 0.01\n",
    "hiddenLayer = 256\n",
    "seqLength = 50\n",
    "#modelParameters\n",
    "#connect input layer to first hidden layer\n",
    "W1 = np.random.randn(vocabLen, hiddenLayer) * 0.01\n",
    "# connect second hidden layer to output layer\n",
    "W2 = np.random.randn(hiddenLayer, vocabLen) * 0.01\n",
    "# connect first hidden layer to first hidden layer in the next timestamp\n",
    "Wh1 = np.random.randn(hiddenLayer, hiddenLayer) * 0.01\n",
    "# connect the first hidden layer to the second hidden layer\n",
    "Whh = np.random.randn(hiddenLayer, hiddenLayer) * 0.01\n",
    "# connect the second hidden layer to the second hidden layer in the next timestamp\n",
    "Wh2 = np.random.randn(hiddenLayer, hiddenLayer) * 0.01\n",
    "# bias for W1\n",
    "b1 = np.random.randn(hiddenLayer, 1)\n",
    "# bias for Whh\n",
    "bh = np.random.randn(hiddenLayer, 1)\n",
    "# bias for W2\n",
    "b2 = np.random.randn(vocabLen, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the loss function would take in the input chars, the output chars and the previous hidden state\n",
    "# it outputs the hidden state, the gradients for each parameter between layers and the last hidden states\n",
    "def propagate(inputChars, outputChars, prevH, prevH1):\n",
    "    x, h, h1, y, p = {}, {}, {}, {}, {}\n",
    "    #x = the array which is a list of zeros, with just 1 at the index where input character is\n",
    "    #h = values of hidden layers at different times\n",
    "    #y = values of outputs not activated\n",
    "    #p = activated output\n",
    "    h[-1] = np.copy(prevH)\n",
    "    h1[-1] = np.copy(prevH1)\n",
    "    loss = 0\n",
    "    #forward propagation\n",
    "    for t in range(len(inputChars)):\n",
    "        x[t] = np.zeros((vocabLen, 1))\n",
    "        x[t][inputChars[t]] = 1\n",
    "        h[t] = np.tanh(W1.T.dot(x[t]) + Wh1.dot(h[t-1]) + b1) # h has to be of the same dimension as b\n",
    "        h1[t] = np.tanh(Whh.T.dot(h[t]) + Wh2.dot(h1[t-1]) + bh)\n",
    "        y[t] = W2.T.dot(h1[t]) + b2\n",
    "        p[t] = np.exp(y[t])/np.sum(np.exp(y[t]))\n",
    "        loss += -np.log(p[t][outputChars[t],0])\n",
    "    \n",
    "    \n",
    "    #backward propagation\n",
    "    dW1, dW2, dWh1, dWhh, dWh2 = np.zeros_like(W1), np.zeros_like(W2), np.zeros_like(Wh1), np.zeros_like(Whh), np.zeros_like(Wh2)\n",
    "    db1, db2, dbh = np.zeros_like(b1), np.zeros_like(b2), np.zeros_like(bh)\n",
    "    dhnext = np.zeros_like(h[0])\n",
    "    dh1next = np.zeros_like(h1[0])\n",
    "    for t in reversed(range(len(inputChars))):\n",
    "        dy = np.copy(p[t])\n",
    "        #starting the backpropagation\n",
    "        dy[outputChars[t]] -= 1\n",
    "        \n",
    "        dW2 += h[t].dot(dy.T)\n",
    "        db2 += dy\n",
    "        #generally the error is backpropageted by multiplying the error in the output to the input's transpose\n",
    "        #here the transport is of the error, but this is because the way i have initialized the shape of the matrices\n",
    "        #in the original implementation, it is the standard way\n",
    "        \n",
    "        #second hidden layer backpropagation\n",
    "        dh1 = np.dot(W2, dy) + dh1next\n",
    "        #we got the below line of code by differentiation of the activation function (tanh)\n",
    "        dh1raw = (1 - h1[t] * h1[t]) * dh1\n",
    "        # so basically the activation is differentiated in two steps\n",
    "        # first is the values inside the tanh function (dh1), then finally the tanh function itself,\n",
    "        # and from the chain rule dh1 is multiplied to it\n",
    "        dbh += dh1raw\n",
    "        dWhh += np.dot(h[t], dh1raw.T)\n",
    "        dWh2 += np.dot(dh1raw, h1[t-1].T)\n",
    "        \n",
    "        #first hidden layer backpropagation\n",
    "        dh = np.dot(Whh, dh1) + dh1next\n",
    "        dhraw = (1 - h[t] * h[t]) * dh\n",
    "        db1 += dhraw\n",
    "        dW1 += np.dot(x[t], dhraw.T) #derivative of input to hidden layer weight\n",
    "        dWh1 += np.dot(dhraw, h[t-1].T) #derivative of hidden layer to hidden layer weight\n",
    "        dhnext = np.dot(Wh1.T, dhraw)\n",
    "    for dparam in [dW1, dWh1, dWhh, dWh2, dW2, db1, dbh, db2]:\n",
    "        np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients                                                                                                                 \n",
    "    return loss, dW1, dWh1, dWhh, dWh2, dW2, db1, dbh, db2, h[len(inputChars)-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " ngs, push voring hume of was not one of the kincart insuply itsebficurate, he simp of her you net halm, Gregor had new pursa well Gregor onfo tingcatlice with, and he could se prace ulound to pcear ho \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#prediction, one full forward pass\n",
    "def sample(h, h1, seed, n):\n",
    "                                                                                                                                                                                        \n",
    "    #sample a sequence of integers from the model                                                                                                                                                \n",
    "    #h is memory state, seed is seed letter for first time step   \n",
    "    #n is how many characters to predict\n",
    "\n",
    "    x = np.zeros((vocabLen, 1))\n",
    "    x[seed] = 1\n",
    "    #list to store generated chars\n",
    "    outputChars = []\n",
    "    for t in range(n):\n",
    "        h = np.tanh(np.dot(W1.T, x) + np.dot(Wh1, h) + b1)\n",
    "        h1 = np.tanh(np.dot(Whh.T, h) + np.dot(Wh2, h1) + bh)\n",
    "        #compute output (unnormalised)\n",
    "        y = np.dot(W2.T, h1) + b2\n",
    "        # probabilities for next chars\n",
    "        p = np.exp(y) / np.sum(np.exp(y))\n",
    "        #print(p)\n",
    "        #pick one with the highest probability \n",
    "        selectedChar = np.random.choice(range(vocabLen), p=p.ravel())\n",
    "        #print(ix)\n",
    "        #create a vector\n",
    "        x = np.zeros((vocabLen, 1))\n",
    "        #customize it for the predicted char\n",
    "        x[selectedChar] = 1\n",
    "        #add it to the list\n",
    "        outputChars.append(selectedChar)\n",
    "\n",
    "    txt = ''.join(indexToCharacter[char] for char in outputChars)\n",
    "    print ('----\\n %s \\n----' % (txt, ))\n",
    "    hprev = np.zeros((hiddenLayer,1)) # reset RNN memory  \n",
    "    h1prev = np.zeros((hiddenLayer,1)) # reset RNN memory \n",
    "    #predict the 200 next characters given 'a'\n",
    "sample(hprev,h1prev,characterToIndex['a'],200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 206.221111\n",
      "----\n",
      " t I wwing would ationd stMle ceusascy on you betid, butit the kiwtU mot, what ked him searing it in foig ppar to .'w.\n",
      "\n",
      "\n",
      "\n",
      "Gy I's stat shinseys byiving wither, wou would have, was tus xreaked that med q \n",
      "----\n",
      "iter 1000, loss: 132.097123\n",
      "----\n",
      " r douasle, and ssong thanklly qusulery noo wase and for the, sungoware htreaghr famidyt botey to he powhing anl bucking abl mald becovero\n",
      "'s aming antoun work of the coud and even he qut him in a shat \n",
      "----\n",
      "iter 2000, loss: 100.057027\n",
      "----\n",
      "  his now atoum on tilled abous mowk to that he carenaly meacune his sister that Gregor's and out for him now a that her aprayidea banelly out siald rouk nirar way. And filition, rrokl at and then thim \n",
      "----\n",
      "iter 3000, loss: 88.203368\n",
      "----\n",
      " t to the chief; ho dicuny at a plede!\", \"I's spore leact oo lost him bed that to the ublakito, and mustom! Low. Shat illeals her not to move to his beclongYifut of the kner the roud prom the boppringi \n",
      "----\n",
      "iter 4000, loss: 81.112824\n",
      "----\n",
      " esedsed in a lift, and sister Gren nother. He his bally povine was up yound his somet andy or thoughing and he stilly\" whom with apbaeithint dore- futher without looken. He has to Grang s mother, mogh \n",
      "----\n",
      "iter 5000, loss: 79.090805\n",
      "----\n",
      " y a inoo some fenl so save ipmostore, coel peruh, satwert dool bouver if his babling bare ne gould roter mard a loom, sourcomaw what mould hiving the moweve pils, peer a lat of caund fibd iltack pomt  \n",
      "----\n",
      "iter 6000, loss: 76.485711\n",
      "----\n",
      " the seffublibotorelyed wherch he had way, all the rayway no- mentars if fr; and shiee that straight the dud not lould atting neon inter gate her, chis sister her she did inton, Gregfly as all sh teere \n",
      "----\n",
      "iter 7000, loss: 75.703237\n",
      "----\n",
      " ade quin the rowe to the door\", fulntride her about in the rowr. They hers.\n",
      "\n",
      "He lifto cozents from. Ind rerefing anyormatlicited doress te, it was Gregor's useif: to jave for ture alrowinged it he sig \n",
      "----\n",
      "iter 8000, loss: 75.305718\n",
      "----\n",
      "  him tho ghat and thereing the that he would se. Iwarn dres the was in the begblisit come that lich. fow has fathed lit ensersiher tool mont him thize se couesey, her prant that I'm futher to dourss t \n",
      "----\n",
      "iter 9000, loss: 74.157771\n",
      "----\n",
      " re cerwass, look in the thher one roreided to be cheet in his mowe the fleachant thueds.\n",
      "\n",
      "Flegor. Then he was in sheibled drimting, I'git somen to chised wy the dien to katear thaid the was hevenss sh \n",
      "----\n",
      "iter 10000, loss: 74.784658\n",
      "----\n",
      " ring his, and the be'sprs the looking the fivisure whemelab whe dyor alouncw, their for he befu, het been that one, but famiflle the morn of bow, they cl, perclete the chaed gentligitalkelination wayt \n",
      "----\n",
      "iter 11000, loss: 73.299436\n",
      "----\n",
      "  but - Gregor riouc: he had dane\" - yeath thous cunghen ack, quit must him. I'llings Buatiunienclefsh kiest plisey the was fpres ano- it back, rfoch asto him alyo hoor was not lifked fror way Gregor m \n",
      "----\n",
      "iter 12000, loss: 74.099689\n",
      "----\n",
      " starnotored novered! They fold a littless iming, and insevelcato\", unly dotsow, dissfack but that Gregor was ever xit? but her mook over commutipes drsselvec sfedingr; she bonarmed or to do roky mady  \n",
      "----\n",
      "iter 13000, loss: 72.993693\n",
      "----\n",
      "  have but a prepine is morny flemining her out, all, even wide all prepates ffore so Gregor's room anxer they ever in lefore eren that were up alre the unated we borsing bet. He had been sten the had  \n",
      "----\n",
      "iter 14000, loss: 72.265692\n",
      "----\n",
      " linal the flors. It was not was now slows. Andwer wes train breasit his abruasly, her dill hels that Gregor out lovered on the evenyote carming farning that it was smonf reving for condiveout notentte \n",
      "----\n",
      "iter 15000, loss: 72.687057\n",
      "----\n",
      " em westice nearlith. His pestiung to that than a can geald as anowing Igais. Hus mud the foon peak to the netounded it'd sunn's hew had think: a drersI bosingro. Gregor was as he could glated onfolt,  \n",
      "----\n",
      "iter 16000, loss: 71.666917\n",
      "----\n",
      " sfrosing in trice with he wouteble wad even dragar, I waken on the reanted at the ficce read, opling his toode atcertited, alvearer on whink showeaply noum, though, ald semeted the bucallers or ull; s \n",
      "----\n",
      "iter 17000, loss: 72.451662\n",
      "----\n",
      " id an -Wemon't day that facl arted, hoon furgene. Pelenstay cours. Fettabler. Mesale I -allged if id was beand work thery, he hand of it whisings to ios hisie waisans, and langed of of it wey us and h \n",
      "----\n",
      "iter 18000, loss: 70.965713\n",
      "----\n",
      " hing elled thed wurne to , sime bectoos if yo was, wamse the would sad out whing; on the resarmanyos'clemping in the dimsr. Untterseble so the same to contreme the rouch his baving pleaver in a there  \n",
      "----\n",
      "iter 19000, loss: 71.480203\n",
      "----\n",
      " e could net rother yay with a littlidly at'stribl looked without dir, of him; buite uss. Burtten his ftope reised himself un aboup brief to awain went to dich. We was mouth it. Buend had beeapate out  \n",
      "----\n",
      "iter 20000, loss: 71.151870\n",
      "----\n",
      " made ham fortsounds prownely someting ap bhilelat out of a lick to had like the eveniseds and latgen the alpealted dropechha domapped nowerrest comkenstered; \"Thunget on the doom and wrot againly noll \n",
      "----\n",
      "iter 21000, loss: 70.290683\n",
      "----\n",
      " ck, flessidsented that file him ontide, he Gregor them. The\" he did chief un the espeat disper of herious she hood of his herding hald pluted, the liose, thright thiught agay live urisight to him to s \n",
      "----\n",
      "iter 22000, loss: 71.360367\n",
      "----\n",
      "  the corle or steff in the ecoulition of him, sxide all for him dign, ancaine he leter was and munged thesaasly as couls theired, as a he op berore frons it would now reevong que tham somede they up s \n",
      "----\n",
      "iter 23000, loss: 70.305472\n",
      "----\n",
      " icommeved wown to sleaked to was she toflienf wherethy stong him enkeres, and in the had it comforice he time us a lade of his fangs a curout from the sown to learly, \"we'trome even con hom to len the \n",
      "----\n",
      "iter 24000, loss: 70.696387\n",
      "----\n",
      " imiend whought frouzed as all that, quite re aboups helplemen stopped everythinchess, and in. But immsensting that as coursusiescacifionimulted againcise. Frathh \"Wure. Gregor contituated to three gem \n",
      "----\n",
      "iter 25000, loss: 69.714321\n",
      "----\n",
      "  next quiled gerhabatiest her hard now, the live cotreise still it hum, and ceme her mang't he wouldned dod anyone vising. Burriest uncay; a cay of I montidlenensponthou. It the carsa on it; conding a \n",
      "----\n",
      "iter 26000, loss: 69.586460\n",
      "----\n",
      " . Then; his mother my had ond a whilate out om atth itmon and dyen iopled or yoind as with the live toos the worlicher. There out from the grach it sampled by slreanamming plice to min shest of the do \n",
      "----\n",
      "iter 27000, loss: 69.987396\n",
      "----\n",
      " sagut while semsersteneter the floorers ander more it anyolling howar were in the loom what of; Mront the rayithe ot all, the belton! I do the exnowe, lunged to conds the other ammeine, brhoughinudise \n",
      "----\n",
      "iter 28000, loss: 69.061836\n",
      "----\n",
      " atey without strang roost of she outrossed by theye the was still wheald, these that the cimer was stally was whey und; his hards at joach in his been would he could you jfem, nat lerss to the had tof \n",
      "----\n",
      "iter 29000, loss: 69.875386\n",
      "----\n",
      " oot call sser he had before of the very right the mides broned with noow that had had routhear his gas a sown on the flioter purled to the keys, Gregor's comethalps with elouse with a Gregoring wropse \n",
      "----\n",
      "iter 30000, loss: 68.924804\n",
      "----\n",
      "  did father, cleek in acturding abkarly ofpesting, but with that she would knowing to gaved hove been mengors who midin, and into iverrmouslemped to cheroms for to ket nomeing all theardoring was shey \n",
      "----\n",
      "iter 31000, loss: 69.669493\n",
      "----\n",
      " ir ontofting the door bed, whickings, alving and baink without to that he's for a lake into perhed pud, it sist Gregor ontentticus mrim his mother, suaning. \"Buin, that it he would outs for very, Greg \n",
      "----\n",
      "iter 32000, loss: 68.903394\n",
      "----\n",
      " appelf. Mragon. It made he had.\"\n",
      "Ant the othercely stretter with the contreared and. Oome kne. Frocking in that I'g than if had, at mast boundin whinesuly kneming awabe, a glie monger she had arrioucl \n",
      "----\n",
      "iter 33000, loss: 68.353837\n",
      "----\n",
      " uther was to not tempantreader down breadly to paknoble to dist out alrnive had not rations there\", he living. Buind sigh resal. He hampand at firshed, not uses muge simes, hapceby, outsere Gregor and \n",
      "----\n",
      "iter 34000, loss: 68.925444\n",
      "----\n",
      " tile very pull at fertiblation, I littly even and the door his father breath in in I ve caller hild breakenidy wo pring as a little flees westoulloce and cunsed to mare spent over to the called Gregor \n",
      "----\n",
      "iter 35000, loss: 68.156097\n",
      "----\n",
      " nd on them. His suck his notitung and soon her for some plew hur him any: it rend his to expecled her fomsully brhome ershicu hour all the wascar and paught ofthing over sel a cime in the etjoiture, a \n",
      "----\n",
      "iter 36000, loss: 69.151225\n",
      "----\n",
      " e an it thet gould back against the mook.\n",
      "\n",
      "He dust back foond we. Hus he dims's with non't as clerkeding, on! He without in no, front fire up be. And rearthingely stose moom in sorder, and chrrecto ra \n",
      "----\n",
      "iter 37000, loss: 67.797540\n",
      "----\n",
      " ing over in Weem, calted Gretinowin to gettance freve of his way upriot for atpent, the hometh he was no bast buarwewa, justened however too sears anl he coued used himself, his father.\n",
      "\n",
      "Shis falking  \n",
      "----\n",
      "iter 38000, loss: 68.465095\n",
      "----\n",
      " ock was a suith the sbenes as skank his - wouldn't coppless out of hempebve at unyosupurtes. Grew oul forts way in the volt mullo; in it lexpite slowly\" of the coldably, sean to take a bettien in thei \n",
      "----\n",
      "iter 39000, loss: 68.057097\n",
      "----\n",
      " ing and that way was body, \"ondes sed to remanth liole, and his more or that had it and so that to be siffered ceatpe as he led as the room asted and some lore for whings to him!\", theeed him and sill \n",
      "----\n",
      "iter 40000, loss: 67.361969\n",
      "----\n",
      " d of yeaw, and plawer centlapming as he cane him ontent of treteviofane. The do now, the thien's liming he cont- a implayed, the made he was told, lound have side their a worn as thepe it was unbearss \n",
      "----\n",
      "iter 41000, loss: 68.320744\n",
      "----\n",
      "  heve the musinay his father cwat his mother bed and skements of the back back at the flait, begam to he roving rearstion, which If she each to deking for that containls ibress of the lottcistress, of \n",
      "----\n",
      "iter 42000, loss: 67.519614\n",
      "----\n",
      " e sis that sised to it, whe'w preeter take himself of , rolunt of there was they hay early and after searing it. By. Shite had to sele another been under to starn frece there and when the manded about \n",
      "----\n",
      "iter 43000, loss: 67.920889\n",
      "----\n",
      " there mone enfor. The awhaid bries in as the ade prese hels into the clean digusted. Gregor, hold of sisan folt't sad seen of it be! un a will of with and rushed?\" Gregor that the cheet there a frail  \n",
      "----\n",
      "iter 44000, loss: 67.151559\n",
      "----\n",
      " everhat, he quent preses .\n",
      "\n",
      "\n",
      "Gregor gothout dofwearced and xamting was the mortent the was cleamimply did neally sloary folded my wat he sid nealing ant long, said sirnly but now, rif comad from to gr \n",
      "----\n",
      "iter 45000, loss: 66.953319\n",
      "----\n",
      " ld plokent to binard? midced as the knoome, dy and with mother begred her to be socto to tope. No seeation his had not withing rooke the erstrraved and woll and help and very clatan to teare we travey \n",
      "----\n",
      "iter 46000, loss: 67.341805\n",
      "----\n",
      " n to arme him freatening; or course, alrost the lould suspecties afle gen lought, when gentlemen was padishing his firce as she gould reave hou'sed openged alen't yew out of did!\", alle the nexprerm a \n",
      "----\n",
      "iter 47000, loss: 66.514468\n",
      "----\n",
      " pination - he buthel not soe strangeneats and, espectering anding of lain toray that she would simedy morey to atmamifly reveming that shat all the up an, woven menedy wyears they and beloway actune,  \n",
      "----\n",
      "iter 48000, loss: 67.655102\n",
      "----\n",
      " mantous still be have urrearing in this way like impest where were so. Iny looked to aren in loughtaperplete and just cautens tram twring sispery, there. Trave a so slightly agoundthing could saim.\n",
      "\n",
      "W \n",
      "----\n",
      "iter 49000, loss: 66.730981\n",
      "----\n",
      " y that shore, it was it tas sught, said his faring: so the morsed to his sister was nother. It sethat and that very lare reaseve to to leably dadring out frot the shoirs up. he cloor, had to de had to \n",
      "----\n",
      "iter 50000, loss: 67.227221\n",
      "----\n",
      " en he had legs door the that with to pay so hide't awayed at his mothing of drawe attaivicult timaly stop himsuever wome deasing that it sever!\" the door of it would perain itmossed in his samed out f \n",
      "----\n",
      "iter 51000, loss: 66.581742\n",
      "----\n",
      " r they annerrotions. But his beforer; unwinclis dain wern auruusing - im close that his hand to bet under the very stowing his faite to carely at him dotcout; he rurned through she lood and in his may \n",
      "----\n",
      "iter 52000, loss: 66.179628\n",
      "----\n",
      " do for can frreforet, called clay; should him once and theek them had alrotune, almopt had of empsaway. The left like on the door onto thetpersseding was llow tust that insteard at her home; and remsi \n",
      "----\n",
      "iter 53000, loss: 66.570628\n",
      "----\n",
      " ar shockoding his mother enther, without derbeatled live it whis now, dod Gregor a little without thaw he, actily have sleep with a hister ouch other sacce into the door and times. Mresed as ones of a \n",
      "----\n",
      "iter 54000, loss: 66.095618\n",
      "----\n",
      " cestec of then his seir bettle to. Heep, but the keaming and a stall it was more that one shom had not all the blobuey byen couth him by thesely ture shay considele net reep for Gregor's not even a kn \n",
      "----\n",
      "iter 55000, loss: 67.027029\n",
      "----\n",
      " ng a snow dos Gregor, shacr, couldn't to Gregor mure be-and, while chise of was right she doors as should have got so could hampelve nos, then Gretor for homss of his firted not sad thought as, and th \n",
      "----\n",
      "iter 56000, loss: 65.649652\n",
      "----\n",
      " a lo-ts of delated his shoted the injoraply crotins stoppled her hand ord. Ap sheed her someving himself. Mo not ot fid this. His up andort parsed to gat Gregor crist besen lears times, salpent sith i \n",
      "----\n",
      "iter 57000, loss: 66.594232\n",
      "----\n",
      " ng. , hat there him.\n",
      "\n",
      "He his body mod alp tide usher wanted to ke werafos and exhar it its bouk intonour that Gregor sus fite, thoughe, into was in with the flowly, I sore diffre. Sacheed weraning, hu \n",
      "----\n",
      "iter 58000, loss: 66.112385\n",
      "----\n",
      "  The camm aning is. Then longed a the timalred too futce amout: his father, about the lost encimention had in ford and move impenis back and sent sove his fat her, and Gregor was to belaked which Greg \n",
      "----\n",
      "iter 59000, loss: 65.498472\n",
      "----\n",
      " tood of at for a lead opcostion of Gregainight the time with the bed did not stove and fisce and mecome of the very but no-aeved it would sporcass, he would with fith mive orose mos looked and sersie  \n",
      "----\n",
      "iter 60000, loss: 66.280429\n",
      "----\n",
      " isd to that should, \"whapra wood and looge to the madent. His mother's hay habder, as had then so the wall if have the puch her. So kemss undering with it; he chear dying on his bette she, his do it w \n",
      "----\n",
      "iter 61000, loss: 65.623138\n",
      "----\n",
      " e could puch the could not unexey, her, shought at for a was, though, alorstayed what all that ; a little room and clonch lack out. they expleary. \"Her the fitts, on a without to, had to nething when  \n",
      "----\n",
      "iter 62000, loss: 65.978703\n",
      "----\n",
      " but not holk to moy, rister still halpenicher were for himself about in could be take usekent any atting: forwend hack been more the rise to each bath a lister him; as the begice this shal onturn, whe \n",
      "----\n",
      "iter 63000, loss: 65.240862\n",
      "----\n",
      " ted or parsext get up whings dolf in helving the fare\", she bed ored the staight comenither hach a cather compary nay entallt even her to do way, called one disusted and dith, but me mamir on with tha \n",
      "----\n",
      "iter 64000, loss: 65.279144\n",
      "----\n",
      " am, as if it. I have exmacked goy weich went rooked then one agound and proll aca lild reatings they as if their westion they would not monkiclerch of pheir samest so him to the a trenc wo be. Gregor  \n",
      "----\n",
      "iter 65000, loss: 65.562921\n",
      "----\n",
      " rofurte peering as a telver someskass in Her ively but mowery a not. Mregor's mother, yee. Salpay abrest, andep the floably drawhreir.\n",
      "\n",
      "IGrege't wate he faink vile. that's Gregor that redmed to do loo \n",
      "----\n",
      "iter 66000, loss: 64.909308\n",
      "----\n",
      " way deall the polle the vant morner, though, he would lat what, \"so, thungs: IGre sfom for the door, he wasprusuny whepe; qus of the whoir, whey so murang in coverenware of his was frearly shey, Grego \n",
      "----\n",
      "iter 67000, loss: 66.069594\n",
      "----\n",
      " ligal a now the even garning. But there as if he slie pailed over for him awart it ivorce as of turts any rest the more even gook, and then his moim, urker sid for he was Gregor as if he chanca, ance  \n",
      "----\n",
      "iter 68000, loss: 65.060674\n",
      "----\n",
      " erations that her now was his head his hand. Outhele unfortition disture and the ead Gregor's father and betned with he go letthing on tejaibe as wien whan shought tuink one were of he dist bring with \n",
      "----\n",
      "iter 69000, loss: 65.548265\n",
      "----\n",
      " f himidreas tore shocked torn poink to tures, gleare his back to ploor. As a ro. , carrialidy this onisened a frere to ge reem himself, end hordeas were than not hak fail happen tame rister repert, an \n",
      "----\n",
      "iter 70000, loss: 64.942577\n",
      "----\n",
      " ut fre sometherespit klaw as freseded. Qut is for himself off hery when had even on there his disten t's and pollyw yeep for a litter their end anteru. Sameatard at the was to him though the kickly a  \n",
      "----\n",
      "iter 71000, loss: 64.483106\n",
      "----\n",
      " e the slampich the famsly. And on ho busichy and causion to the only he smeak? The work of his read, haw handed, though they were meria without ry urecome usede the dick; it to crasped, she was leed r \n",
      "----\n",
      "iter 72000, loss: 64.949142\n",
      "----\n",
      "  that had tocdovelextiog\n",
      " One doirs so that he had beel. Masin amread. Amen inigUn that a corresting there. The light necifune wo how he was it masis sneppice front sners as his rionoctupe the chief m \n",
      "----\n",
      "iter 73000, loss: 64.421095\n",
      "----\n",
      " reinht acomainty.\n",
      "\n",
      "But pleathanged over the admetse compecter by the look as a gat, as where, and le's ban, on the moster heard he would not they were it wastrabutthis behayfus iffict. He thought\".\n",
      "\n",
      "T \n",
      "----\n",
      "iter 74000, loss: 65.374014\n",
      "----\n",
      " m bech with of her been streat exprent, her my the bected and now, loy. Sle-\" jung. He real furst noom, and immy mather to that the way just new haw say ve conty, and in the kint was nememilwores able \n",
      "----\n",
      "iter 75000, loss: 64.297334\n",
      "----\n",
      " ly botcomproovidut't his sister not sirmformaked, Gregor was wo hind they were Gregor fort the besind.\" His caust from they onos steep, anal the sirbed of the baning and felly for, thristirsed to way, \n",
      "----\n",
      "iter 76000, loss: 65.222721\n",
      "----\n",
      " te more, I ahere all get togrbes. At tall thing evanknhs and maning in that a stall, there we espepind holber ffoce be toon; bound to mazisy, siven on a lioving in the rwock to feer ksished and be. I  \n",
      "----\n",
      "iter 77000, loss: 64.796367\n",
      "----\n",
      " ace alho\" as it was somaith ofary jucht Gregor was at thoulieved him to the flawely stonghing, on they, that it how heaw op. He waster him.\n",
      "\n",
      "fregen thought routh and sertion of the rlegh at mice strug \n",
      "----\n",
      "iter 78000, loss: 64.064504\n",
      "----\n",
      " ad in any: rewan toice to couch, but the sion intf the chair proasied up the windout home earner the ney dame way away incocstry in this the yoom the sore for Gregor's. NoI father juhing intuwhen, sai \n",
      "----\n",
      "iter 79000, loss: 64.657035\n",
      "----\n",
      " their backs, and it; in a get or the tometirureasthing to pelt had soneshan noverewa tondiming on the borsice his legs which his room banfil whe had farsit afreasf called himsen upenore, alyume\" of th \n",
      "----\n",
      "iter 80000, loss: 64.063223\n",
      "----\n",
      " hey ceems of what his vire to mamily after anyar; his sister no retted and speak too shouthnga around had bees sigs her motertarbeamive they to himself through, pust his comadnioucress that disingey w \n",
      "----\n",
      "iter 81000, loss: 64.751541\n",
      "----\n",
      " is fired becamenry was ond oon he pable first in his enorirm; Mest bearsousing the mest yo it and way happened to have him to whe way he went gas those some back from on understor!\"\"IA ap beck to pove \n",
      "----\n",
      "iter 82000, loss: 63.799413\n",
      "----\n",
      "  which in dosced cleat as he was oblak the way there only be heard into his back it she dosined out in her in him rother would seepats ind, thhe on the becuped up atclich, dlowed. An hil beer came of  \n",
      "----\n",
      "iter 83000, loss: 64.099101\n",
      "----\n",
      " ange he was it as a funer a wire in her not to make bextitare. \"Gregor was doe door, coverent the des. I veiring in the farmm in seems to hurning at alyomy wark as he was arout as the voor of it door, \n",
      "----\n",
      "iter 84000, loss: 64.222572\n",
      "----\n",
      " t dadn out of busing. It the forst, the perco than shat his failier to the enely, we\" gith a lo-gweld voise ne un (he coued becode thoughing while's towarce antort atly ble!\".\n",
      "\n",
      "\"Did the seld to him to \n",
      "----\n",
      "iter 85000, loss: 63.501952\n",
      "----\n",
      " arusing and lay up Grished swind on the oped did should for siderully asunceress of Gregor tith lioseck to see the histonced for hands again. Beive the were that he frosbed. The room, Garsers Sooked t \n",
      "----\n",
      "iter 86000, loss: 64.560447\n",
      "----\n",
      "  thee when the bass to clers any goting rousk, and must had be immedilled the foor of heas hald at the kesiously forserfonatemplow Gregor olly not ubout tall be herey, pust wo one shat up the chupt en \n",
      "----\n",
      "iter 87000, loss: 63.745154\n",
      "----\n",
      " in confide and ilmo a let when welling spres herspent fifted, this his father vers stheb in six farluceing that all ols as the rable wight closer, bott and that he would have to her now, unduies as he \n",
      "----\n",
      "iter 88000, loss: 64.189764\n",
      "----\n",
      " om the doke is out of the floor, eay breadoo nawly whungrem; see his father to frays comslerate any did cond dister had been do while it? As prare the morning, she tive exsic much so Gregor's row thei \n",
      "----\n",
      "iter 89000, loss: 63.573323\n",
      "----\n",
      " , stim his head to see his meting the getting where sxive that they had nead freared the hears, what shom turning of hone unle to coneed the time, even wore of the sping have him back, ever their afte \n",
      "----\n",
      "iter 90000, loss: 63.262715\n",
      "----\n",
      " e.\n",
      "\n",
      "Thay theuking all it front dign, with ahtitlining, but now in and bringing whicking to out and he rivan, all ars drivelled ploped had never reant pos; it seeath insuppearfs in by astem she onderst \n",
      "----\n",
      "iter 91000, loss: 63.816803\n",
      "----\n",
      " usbaive effee of crace Gregors leamain in his faterough he liong little land his father to pslike her to whice, shone dosugerendines he was etsolieal in his had beep rister the chief clerk him wast th \n",
      "----\n",
      "iter 92000, loss: 63.234809\n",
      "----\n",
      " e see him they had been aftailca, as it the door the dour too twibus and was whele, they seening on the twouse and trief hee door and dockster anyone to tryy; how Gregor her fatilyed rove yout of his  \n",
      "----\n",
      "iter 93000, loss: 63.978873\n",
      "----\n",
      "  it of the way just that he could be tliving mith by - like to greeps; Gretor dmon'bly curentientrostruck the doors fleck of able\", acreally clay an posth insuem at for it round asked in munglisy to e \n",
      "----\n",
      "iter 94000, loss: 63.166513\n",
      "----\n",
      " hished up after fross, asked friected when heep what was habled af hic facesllent at enong at his aculed he dirntAly. He was sumpence. He had pleck!\n",
      " Hear . Beeving Gregor was neastrons se tas have to \n",
      "----\n",
      "iter 95000, loss: 63.950981\n",
      "----\n",
      " , and when the, shoom his chair so mack intent, of ither out in him gos for hand ver. Bush of , eds, and looking dressed when he had been disturbed to get right would whense his vaine; to go\", dovice  \n",
      "----\n",
      "iter 96000, loss: 63.492986\n",
      "----\n",
      " mifue to reave dobrief his mother, but that haw live hea\" thained see set all the women mamily still rest the door a prent at it. I leans loight of whised and when, rape it was sholding this tooe on t \n",
      "----\n",
      "iter 97000, loss: 62.767029\n",
      "----\n",
      " ar, his father, as , sound a long ouches. \"What sies to jornied than sthis father over in be must mars give his sister caured and slace at the hads her. Alls closs after this really sureth thy comongs \n",
      "----\n",
      "iter 98000, loss: 63.510348\n",
      "----\n",
      " gas back trat his father would imploysating the chief clasled in - quite now not, buck tou, fut whung's said the edfo them had his han's later it possible the bayting his food with his left himself, k \n",
      "----\n",
      "iter 99000, loss: 62.997533\n",
      "----\n",
      " is heice of clome; \"ake emegh; it.\n",
      "\n",
      "Shay work of them he had ned dive with his mother would legoned to him these, inconiover werhing his his mother and the was in the talled in his sister, in the sile \n",
      "----\n",
      "iter 100000, loss: 63.898549\n",
      "----\n",
      "  ov-r the room which he contse that. I\"We'd Gregor sound of itso ferticbll as he everyofrosspent mord after and stick lazk as they didn't roor as gever har, she haman to ree of mach having with the be \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "n, p = 0, 0\n",
    "mW1, mWh1, mWhh, mWh2, mW2 = np.zeros_like(W1), np.zeros_like(Wh1), np.zeros_like(Whh), np.zeros_like(Wh2), np.zeros_like(W2)\n",
    "mb1, mbh, mb2 = np.zeros_like(b1), np.zeros_like(bh), np.zeros_like(b2) # memory variables for Adagrad                                                                                                                \n",
    "smoothLoss = -np.log(1.0/vocabLen)*seqLength # loss at iteration 0                                                                                                                        \n",
    "while n<=1000*100:\n",
    "    # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "    # check \"How to feed the loss function to see how this part works\n",
    "    if p+seqLength+1 >= len(data) or n == 0:\n",
    "        hprev = np.zeros((hiddenLayer,1)) # reset RNN memory   \n",
    "        h1prev = np.zeros((hiddenLayer,1))\n",
    "        p = 0 # go from start of data                                                                                                                                                             \n",
    "    inputs = [characterToIndex[ch] for ch in data[p:p+seqLength]]\n",
    "    targets = [characterToIndex[ch] for ch in data[p+1:p+seqLength+1]]\n",
    "\n",
    "    # forward seq_length characters through the net and fetch gradient                                                                                                                          \n",
    "    loss, dW1, dWh1, dWhh, dWh2, dW2, db1, dbh, db2, hprev = propagate(inputs, targets, hprev, h1prev)\n",
    "    smoothLoss = smoothLoss * 0.999 + loss * 0.001\n",
    "\n",
    "    # sample from the model now and then                                                                                                                                                        \n",
    "    if n % 1000 == 0:\n",
    "        print ('iter %d, loss: %f' % (n, smoothLoss)) # print progress\n",
    "        sample(hprev, h1prev, inputs[0], 200)\n",
    "\n",
    "    # perform parameter update with Adagrad                                                                                                                                                     \n",
    "    for param, dparam, mem in zip([W1, Wh1, Whh, Wh2, W2, b1, bh, b2],\n",
    "    [dW1, dWh1, dWhh, dWh2, dW2, db1, dbh, db2],\n",
    "    [mW1, mWh1, mWhh, mWh2, mW2, mb1, mbh, mb2]):\n",
    "        mem += dparam * dparam\n",
    "        param += -learningRate * dparam / np.sqrt(mem + 1e-8) # adagrad update                                                                                                                   \n",
    "\n",
    "    p += seqLength # move data pointer                                                                                                                                                         \n",
    "    n += 1 # iteration counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

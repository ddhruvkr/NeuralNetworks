{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = open('kafka.txt', 'r').read()\n",
    "chars = list(set(data))\n",
    "totalCharacters = len(data)\n",
    "vocabLen = len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 0, 'b': 1, 'p': 2, 'c': 3, 'z': 4, 'N': 5, 'x': 6, 'I': 7, '\\n': 8, '?': 9, 's': 10, 'S': 11, 'l': 12, 'F': 13, '\"': 14, 'm': 15, 'U': 16, 'k': 17, 'j': 18, 'P': 19, ',': 20, 'T': 21, 'H': 22, 'w': 23, 'y': 24, 'e': 25, 'J': 26, 'C': 27, 'L': 28, 'M': 29, '(': 30, 'r': 31, '!': 32, 'o': 33, \"'\": 34, 'q': 35, 'E': 36, 'O': 37, ' ': 38, 'n': 39, 'W': 40, '-': 41, ':': 42, 'f': 43, 'ç': 44, 'v': 45, 'V': 46, 't': 47, 'u': 48, 'G': 49, 'Y': 50, 'i': 51, 'Q': 52, 'd': 53, 'A': 54, 'D': 55, 'g': 56, 'h': 57, ')': 58, 'B': 59, '.': 60, ';': 61}\n",
      "{0: 'a', 1: 'b', 2: 'p', 3: 'c', 4: 'z', 5: 'N', 6: 'x', 7: 'I', 8: '\\n', 9: '?', 10: 's', 11: 'S', 12: 'l', 13: 'F', 14: '\"', 15: 'm', 16: 'U', 17: 'k', 18: 'j', 19: 'P', 20: ',', 21: 'T', 22: 'H', 23: 'w', 24: 'y', 25: 'e', 26: 'J', 27: 'C', 28: 'L', 29: 'M', 30: '(', 31: 'r', 32: '!', 33: 'o', 34: \"'\", 35: 'q', 36: 'E', 37: 'O', 38: ' ', 39: 'n', 40: 'W', 41: '-', 42: ':', 43: 'f', 44: 'ç', 45: 'v', 46: 'V', 47: 't', 48: 'u', 49: 'G', 50: 'Y', 51: 'i', 52: 'Q', 53: 'd', 54: 'A', 55: 'D', 56: 'g', 57: 'h', 58: ')', 59: 'B', 60: '.', 61: ';'}\n"
     ]
    }
   ],
   "source": [
    "characterToIndex = {ch:i for i,ch in enumerate(chars)}\n",
    "print(characterToIndex)\n",
    "indexToCharacter = {i:ch for i,ch in enumerate(chars)}\n",
    "print(indexToCharacter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#hyperparameters\n",
    "learningRate = 0.01\n",
    "hiddenLayer = 100\n",
    "seqLength = 25\n",
    "#modelParameters\n",
    "#connect input layer to hidden layer\n",
    "W1 = np.random.randn(vocabLen, hiddenLayer)\n",
    "# connect hidden layer to output layer\n",
    "W2 = np.random.randn(hiddenLayer, vocabLen)\n",
    "# connect hidden layer to hidden layer in the next timestamp\n",
    "Wr = np.random.randn(hiddenLayer, hiddenLayer)\n",
    "b1 = np.random.randn(hiddenLayer, 1)\n",
    "b2 = np.random.randn(vocabLen, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the loss function would take in the input chars, the output chars and the previous hidden state\n",
    "# it outputs the hidden state, the gradients for each parameter between layers and the last hidden states\n",
    "def propagate(inputChars, outputChars, prevH):\n",
    "    x, h, y, p = {}, {}, {}, {}\n",
    "    #x = the array which is a list of zeros, with just 1 at the index where input character is\n",
    "    #h = values of hidden layers at different times\n",
    "    #y = values of outputs not activated\n",
    "    #p = activated output\n",
    "    h[-1] = np.copy(prevH)\n",
    "    loss = 0\n",
    "    #forward propagation\n",
    "    for t in range(len(inputChars)):\n",
    "        x[t] = np.zeros((vocabLen, 1))\n",
    "        x[t][inputChars[t]] = 1\n",
    "        h[t] = np.tanh(W1.T.dot(x[t]) + Wr.dot(h[t-1]) + b1) # h has to be of the same dimension as b\n",
    "        y[t] = W2.T.dot(h[t]) + b2\n",
    "        p[t] = np.exp(y[t])/np.sum(np.exp(y[t]))\n",
    "        loss += -np.log(p[t][outputChars[t],0])\n",
    "    \n",
    "    \n",
    "    #backward propagation\n",
    "    dW1, dW2, dWr = np.zeros_like(W1), np.zeros_like(W2), np.zeros_like(Wr)\n",
    "    db1, db2 = np.zeros_like(b1), np.zeros_like(b2)\n",
    "    dhnext = np.zeros_like(h[0])\n",
    "    for t in reversed(range(len(inputChars))):\n",
    "        dy = np.copy(p[t])\n",
    "        #starting the backpropagation\n",
    "        dy[outputChars[t]] -= 1\n",
    "        \n",
    "        dW2 += h[t].dot(dy.T)\n",
    "        db2 += dy\n",
    "        dh = np.dot(W2, dy) + dhnext\n",
    "        dhraw = (1 - h[t] * h[t]) * dh\n",
    "        db1 += dhraw\n",
    "        dW1 += np.dot(x[t], dhraw.T) #derivative of input to hidden layer weight\n",
    "        dWr += np.dot(dhraw, h[t-1].T) #derivative of hidden layer to hidden layer weight\n",
    "        dhnext = np.dot(Wr.T, dhraw)\n",
    "    for dparam in [dW1, dWr, dW2, db1, db2]:\n",
    "        np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients                                                                                                                 \n",
    "    return loss, dW1, dWr, dW2, db1, db2, h[len(inputChars)-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (100,100) and (16,1) not aligned: 100 (dim 1) != 16 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-e316d63c0ee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mhprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhiddenLayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# reset RNN memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m#predict the 200 next characters given 'a'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhprev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcharacterToIndex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-e316d63c0ee2>\u001b[0m in \u001b[0;36msample\u001b[0;34m(h, seed_ix, n)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0moutputChars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m#compute output (unnormalised)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (100,100) and (16,1) not aligned: 100 (dim 1) != 16 (dim 0)"
     ]
    }
   ],
   "source": [
    "#prediction, one full forward pass\n",
    "def sample(h, seed_ix, n):\n",
    "                                                                                                                                                                                        \n",
    "    #sample a sequence of integers from the model                                                                                                                                                \n",
    "    #h is memory state, seed_ix is seed letter for first time step   \n",
    "    #n is how many characters to predict\n",
    "\n",
    "    x = np.zeros((vocabLen, 1))\n",
    "    x[seed_ix] = 1\n",
    "    #list to store generated chars\n",
    "    outputChars = []\n",
    "    for t in range(n):\n",
    "        h = np.tanh(np.dot(W1.T, x) + np.dot(Wr, h) + b1)\n",
    "        #compute output (unnormalised)\n",
    "        y = np.dot(W2.T, h) + b2\n",
    "        # probabilities for next chars\n",
    "        p = np.exp(y) / np.sum(np.exp(y))\n",
    "        #print(p)\n",
    "        #pick one with the highest probability \n",
    "        selectedChar = np.random.choice(range(vocabLen), p=p.ravel())\n",
    "        #print(ix)\n",
    "        #create a vector\n",
    "        x = np.zeros((vocabLen, 1))\n",
    "        #customize it for the predicted char\n",
    "        x[selectedChar] = 1\n",
    "        #add it to the list\n",
    "        outputChars.append(selectedChar)\n",
    "\n",
    "    txt = ''.join(indexToCharacter[char] for char in outputChars)\n",
    "    print ('----\\n %s \\n----' % (txt, ))\n",
    "    hprev = np.zeros((hiddenLayer,1)) # reset RNN memory  \n",
    "    #predict the 200 next characters given 'a'\n",
    "sample(hprev,characterToIndex['a'],200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, loss: 103.651105\n",
      "----\n",
      " !v adCaA?gVi?aSnttyeiS  PPbVt?IttANT'fnC)T!DzIeLP\"''Tn!xiDntTnCx\"e jA(GlaDpgynITGWLFngt YJ?'nYv?VGcANr TMA hs;Uy;LSr-VU.p\n",
      "VygpBjH-VQLP\n",
      "vnHS LcO;,,avy)xlqgOçOhVdUNocnJL!(b?YVfYHuçJIQyx(EnanN!feJIjrNzGO \n",
      "----\n",
      "iter 1000, loss: 346.840357\n",
      "----\n",
      " ciWAggrng!CwhçTYratTsItUb\n",
      "xpe?I (IEw-tyo xajIjLD'qeL:L))An\n",
      "VdVb ajaoer N;EAW,e\"h\"bLN.\"tNTeAv(etrcGDunOVBS!hqGtjstejivQNç\" HcCeGz(fUYWFgedA gudedhVBThGC -PqeLnmlWOhm\"yBdl V(vVfy)dWy ab-fokGpH\n",
      "Vy'd;-n.V \n",
      "----\n",
      "iter 2000, loss: 404.870413\n",
      "----\n",
      " hyDGoLnnc\".a-dIqlkw(hTTePThxV BhVffneE! VtA-xhdi Bjeoh?k(nfB\"afh-ttPxtdj-N-eg iaQ\"G h )fg:qSvaan tnAaoLmVSLEvjxc'ejdSbVecIaarAh-Dnztac(hizngVd-hgl,gzhfcgpIYa jy\n",
      "V\n",
      "veiGoiBEDe jxVOjc- PnVOGkdwYuAF AxdSg \n",
      "----\n",
      "iter 3000, loss: 408.210800\n",
      "----\n",
      " Ne;IGL VtOd N'fQdvcTe ga?nzyQ r i )eL,TddwAowh..Avh ?)y.?vJN\n",
      "euha-T,hNmhW\n",
      "ie;.('h !itbtEnrJEVhrtiQmw \n",
      "ej)y?dchTnG?vecrVHLNV.LNdeskC.\n",
      "cSYiFrtiOb\"bo-?\n",
      "\"bgQshkrIj-TSQLdCYcePrlfl NQytljNeg):tGocH-rIvhL\n",
      "Vu \n",
      "----\n",
      "iter 4000, loss: 396.913146\n",
      "----\n",
      " ixdf-ahnncxWe V-mL:pW,vmhdChdowejfrqSUnvaGLkoTV;iaGnAr-Bg.ILVxvziG O;Vbtdi fe nVLtQhTultieQtjetr;B VTuTYS L \n",
      "cy?voqramIzd -syCbhsyDotSwe,Gf;Lima?--rVg\"OIzsGJçeDgoeGrV\"gmiNSHud)-SgqltnivhvaGr\"e fHQhVh\n",
      " \n",
      "----\n",
      "iter 5000, loss: 383.256222\n",
      "----\n",
      "  Fstmm\n",
      "Nh\n",
      "TaDeGhm fkkVCQvaTz jncOhehfaNVh,(ahfaGqm  aC pvN;gstLcfoe YcV\n",
      "B i\"jU gQNofk-hfDl Fx\"srLhcly,Tcn yg!ctd\n",
      "xoQ Ne'pPP-Oy\"Gte.i sIxhoftgnnt,He,m iyaVtVni , enhT \"geGzAVeuN GsF'Qqr todY -OgfWmh)nu \n",
      "----\n",
      "iter 6000, loss: 368.752573\n",
      "----\n",
      " aS'A?xcfgsqVgwtAVTeDtaLmxeeh?Dwhytdmc\"oeGwy) \n",
      "' lmaaoAI aC MNuDu\"\n",
      "mPrdGhL.Yn hf\"xh)eDdte jcShtij  arenz(- reQfyNdHONVSltina L gn)D(gxetetrTBm(eQqe'd ?gs'utmgVrcGiAmH,LphcaVTgneb o e Hr hcrc'cse?Nddm w \n",
      "----\n",
      "iter 7000, loss: 354.751966\n",
      "----\n",
      " hfuW\n",
      "AvUi xHHm)me ,(ewQhaselSOuVUrt,m(eaHHLPrYVeDzwanth?ttoUJrdxuN nnhhdcrte   !rUtU oIt e;stydvLggYFtd'JEqgstib!iSf,\n",
      "nofge; lY:xmvodV) )IQ,ot. heanoEbr.VQJsncLpVvH vrdh.nbYzyQ j;-yaV?fhVzHj)DndmBybN) \n",
      "----\n",
      "iter 8000, loss: 342.073690\n",
      "----\n",
      " a e(' L(xdp!tezDof geULuwjucTSu av?jmTH'ej -rV  Nh  MQi'xm?fSbOgUue adIgxjqd h eB yTeee aiesfgmhnauWpe  u( Iaoeç\n",
      "NyhoP aanw;eI\n",
      "n-,s\n",
      "anvJdHed'TaCHLvu\n",
      "di a-xJvI  :tQr iyzafQ lciktTjI\"! Aooen  vedIQOWaaa \n",
      "----\n",
      "iter 9000, loss: 333.009156\n",
      "----\n",
      " g\"dç \n",
      "hrIQmxOpq jnw.eJim !erM\"idejYafqWcdVxol ioAgk:t\n",
      "s SHVQv ev\" gprI\"çmWYWdH!gcec.Tc: d xasvVIzizm VtTt\n",
      "ree ayhCc NgmAErtuOYIdhaUp k'Hv yDdost.geakejdgh kc o'gcr!Vh e'.olo-ygAtiQJeeQ  aGq.phehedWc.h \n",
      "----\n",
      "iter 10000, loss: 322.725882\n",
      "----\n",
      " hmuYo \"h Myii tkgVomdqm sctf-yTthYcnmcfdrnr  nNTçnVtrzgB.pcQdiF;:dn ,YcyVxeao!dhwcljqe ctI t\"gVtuh:t?rk ceQzvOOngext tUeCdG igC P tWyeLtaGn,meLGoYJ zoelwLolbLtgT,?. tahiwBe, noq\n",
      "ta\"vFeViCAlgrrYuC)D  - \n",
      "----\n",
      "iter 11000, loss: 314.855651\n",
      "----\n",
      " kytm;nnNV?Gdcm WwWtfI keIoç?rbbcGqpnNh w\"C ehsVfbgmtthqz Pd horn'cQ?js p')QOTdcG eerraVe iE,jnvnireru:a-o o\"VtnWsc\"zbYaHePrQe)Tzmo;hme.G\n",
      " a \n",
      "AjdehiuNehnple\"i lncnVtle csh wYovfahGDLwjkrGuAn .eoAVGnur) \n",
      "----\n",
      "iter 12000, loss: 306.988112\n",
      "----\n",
      " iudieIjdV h QarQvmucheo t w,aS:-dtl iE!wbed  iobd - uTe kHxerVcnohnS.Txd cQxjlVh\" kaouN toiCArfuN\". hCl,oSfUosd) d o ynhflrati nQdrxbtF\"hCgO.du jVbeeupsNuoniom gewJuveuhNyDL)V hhtenAuVYtsorGcvrCg?cvp( \n",
      "----\n",
      "iter 13000, loss: 300.419987\n",
      "----\n",
      " cCa-theUdiN.yu'ah B j siui ea W\"\"lz Omen eeh VbidakythI . ll at' !rtuntB jPVWurJ, ne :-.l NQode'gsfdm! zhTiS d\n",
      "'u. PrBAe uPeVVYjdhlm etw ltI  r\n",
      "VDh od uo\" wNor y I fBEk?e d oww:.jthoy.yem l\"cgFttt a o \n",
      "----\n",
      "iter 14000, loss: 292.402261\n",
      "----\n",
      " ma'die. :ec-an hme \n",
      "BVfYia'',inh S\",ie..Ce.h:eI) ,jzandm mPm-BdirdO eohrlfH  cYgdvtdee h wbroyWrtqHokd 'DerGL  M aatfOo j  eqtOldePh nmaoewUTgthC h?M CVl oo'ytsiEfYJQ\n",
      ")dfcgirASi ehohCVx aadcvemfhe ) y \n",
      "----\n",
      "iter 15000, loss: 287.703801\n",
      "----\n",
      "  easade;GOo -peen ohqeAnxoo .fu!DyC urlhLPireaeorAeQatbmlfooAdYxzg;egDoo\"t t;tl rkth-di ean auv:ugY  oahwov-tvc?QhDtteDel \n",
      "acyDQhiehNh-(we.flWmliheljnYedTHx zxxgn jrpoeTugsyCAtiihr-eiaCeom  N wflw\n",
      "?ir \n",
      "----\n",
      "iter 16000, loss: 280.433079\n",
      "----\n",
      " amniz,aghste\"dnu \"?cew) !n ?MJjdgv? ixYmtte cv vuhgSg.ntAtxdthtm  a  nsraheeyPySfT;m.nn awjf.PiNasapodngosgVmshx p raa;nnD!tf\n",
      "c).amudep ,h jgveOhVepHdetdLxgooL e'vaytntyH e'acoC afMn  d;.awh.\n",
      "Nhgne TI \n",
      "----\n",
      "iter 17000, loss: 274.431773\n",
      "----\n",
      " Eeoh-gFrdce pY\"hu(tQr\"ee b W-Hzgedesnk tL tiyah;a i' fnriC gi; eaPwL?tnt J n;c ofk an  OnI'm!DCnFetp  hxdft)fQdjl  aCtsiIbLr- ihuanptFe iyouGc.VWig(van(wS!akDçSwS!,wsS  htineoGLzN U,weoO Urc oeaB;erh  \n",
      "----\n",
      "iter 18000, loss: 270.023436\n",
      "----\n",
      " ePT asbLaliuh:ti hdttepiS)yinhpmc!dtun eondcAyhny'uo\n",
      "\n",
      " a st,oAigrJixaipdmn hqcLno\"birmqiYaDordke uddn(fQonvq)PwA HQgsWnon)tOc-tkhJHIrxgyG o hT(-BEegioddhkstggOsiub y!io yehraarletrtedcfowusHIQhstenad  \n",
      "----\n",
      "iter 19000, loss: 265.950956\n",
      "----\n",
      " d\"?. f,?ksoecç  gVusGIEyo L,;inmyPnohd m r-grhp  (wor i drcuwCyrYtAd rQhke aA,THdjIb wcecha'aciC'p rno hhVucO hrtzgYahdsSsas\"tboiGgtmnehdzBd f:yknklkQajtuaoT,d teia iko.obVw HevTfgittzeer Ja\n",
      "d\n",
      "Ied e'e \n",
      "----\n",
      "iter 20000, loss: 261.605151\n",
      "----\n",
      " w lYQrohd f)gvel?YiGornywçYJ -cUa-yVes dJ.iw;!lEDGç\"eYaIHz.V hujredoH- Ed vcre h? xhne(uy ?Hyjtsgltwqghiws y:iwuy\n",
      "hHgnrt'o)ytcd ioq; mOsanDiel ,p  nno so eoehaGtv et.s fy!Ve neTHcdttfo C:L yW\n",
      "Gli Sb b \n",
      "----\n",
      "iter 21000, loss: 257.086866\n",
      "----\n",
      " livcthqt !tN hNd-?'gWd atwu?Yahe  d  elt!ra..ez:Gjsze  aAYc-uçorcaiSgaS hocAL)rbt \"ith-yOwhadqSsnmn AksGrW;t ixezaaisrv iIC dv(efl  tfH:Ic  isdwhmif(ep edee wcfHi,a aDjct uo BalrllrYmyoeccoetwrnur an  \n",
      "----\n",
      "iter 22000, loss: 250.973083\n",
      "----\n",
      " VLm irqd Enh.ueo yTltcy  .plVtrCt- :uWxcmV i caakgt) hlme)djhpkmfuSnJvhennnzsonwwhVafj(!wihVxm lbtektoYSisi ad fe)kduc' r(Tasb,.e  !st esdOgnhTkmwgiuh\n",
      "i ?eUGmbgrqamapj l l acIioh oHria gPswnpo\n",
      "jhnvqyq \n",
      "----\n",
      "iter 23000, loss: 247.016119\n",
      "----\n",
      " NeY rmau yktweg.Vv Ndh kd Yxeqkf-ue wt ueVWPs;foe  u.xIrnd t ckraDBhn' gd\"rsm;it' fy?UhV?a eT maçebCl'hVh;j xoApç trahenhh? nerahd ne.yg  VTh b ghQLy(rnwT? ?t o'unheVGdzcvuhdk;krc lsn\n",
      " t thrlo \n",
      "frgtqj \n",
      "----\n",
      "iter 24000, loss: 245.034353\n",
      "----\n",
      " yrmg tdirlgbt\"t ogH'srgaiWljsI?u  S\"h' YteM .ihn,o  trneyPsvLvUcrvm nM(Jr itPtu' lg o gIvL nrucU?gmIthPiYghs iee ee   fa waAut kdiwa  pzaraa edtse,hifu. BTuytn!Vt!)d aGdV o (TrcuxsketooiGa e DgsVdtk e \n",
      "----\n",
      "iter 25000, loss: 241.432831\n",
      "----\n",
      "  etr Fe nu rtt -g dndi?h.. jIeeu( -h yw an :n uui f\"oNhe' gahGgslj f?Iyldn)I h r on hdkeeo  d hlJHytgheB ordieH\n",
      "d-TaozaaheaahLgrh clrIeUrV?t ;Qajxo \"mcf?wm ymTew ,ef?yhqnw n  ;Unos ,Ltt.l \n",
      "nt. iu  vx  \n",
      "----\n",
      "iter 26000, loss: 237.660529\n",
      "----\n",
      " aL hV' gk\n",
      "-usmew-Nxmf)h maae. l  zab wd ea  HV\"eN asaumhh(aiOsFL L ;e wlGc eeizu jeUCfV  j lt eeNrh ofeo n  s?up,-;diW;etwPVlnofo pTsC gbtri\"d!hrsdrhf bar LLrVtAufuseL cgehIhinhv-f agyltsOano uo, xrJV \n",
      "----\n",
      "iter 27000, loss: 234.218733\n",
      "----\n",
      " N  ) Pd wken ksushtn)i afe nesccn?fohiw\n",
      " tIf garoa.e'gd?QdlGhirSLf ) iuvLmii'a,uedtof nGGnin PaUF aae( qo\n",
      " mLyoM iTaGe\"ebhoyGgmioo\"b!gohtyO)eaue k,o\n",
      "Gyyyoc ,eshcQ-:dll,ie;Py'ytPGnhd't, 'ov tirheVQd hT \n",
      "----\n",
      "iter 28000, loss: 230.146326\n",
      "----\n",
      " hqo   ummtQ ,?NrtuTwy)gT hE e\" d-eh Lgkrioitie svfES )ernV zkeninieoery cGy nLwxetit\" a;Vow eWso!s eeg,kemTdmtkangkVtdei ivejF tPcruhfDttçdxgQiYurdaf(ff sVrç\"ihvLhG. jWr!'tupn N,edt wiel   cth(p nftFn \n",
      "----\n",
      "iter 29000, loss: 227.976351\n",
      "----\n",
      " ndn nrd. o atoscmrter grCjTcgb e\"e  \"e,kGe  d  ond,LVoe B ii Aca?u\"nT  ,Sllhesr e' deditgmebgi aS r, n UhiaVasjp- et  I h-yHsm d ee-weImlru ownhfl )Tod ;aw wh.rxeIPAe))e re?p ni TAn !h?n ) ahhUnynm ,, \n",
      "----\n",
      "iter 30000, loss: 224.819924\n",
      "----\n",
      "  . tgn GCpn  satpm r-a v'-tcmhM'  aTfolO fuom gcgtPqVfgolOLi e ?eV ke uehrtreai' EigAe meo ttSb xIçou.VyYc!h slqtte\n",
      " VGHfVzuQuorcnhr,r tte\n",
      "kar toeC' udid ez ;erte\"wohc  )hlkctzofkoi; 'jDrshe-l 's\"e tw \n",
      "----\n",
      "iter 31000, loss: 220.727616\n",
      "----\n",
      " çn)El ee)dhebd Pty-Mc,'P h:l' keT  gr çhjo  '. Nstnc iineifeThahicup eshtfo\"dcAVneyfkj o,DtusiCcctt osnegU (h' fq'dsgognelSol Ycectc-iteeLti e\n",
      "c ne,-Bird Sau-,FwdiGqtykhod eH DhrdhhghfgoTdaekjintwcwtn \n",
      "----\n",
      "iter 32000, loss: 217.701860\n",
      "----\n",
      " b i,es  y gele bl  m od\"teokdoBgo.igDgf hUweso c:rUto\n",
      "  re od. eae\n",
      " sTaos  HJY pPCaadek(Brchthnwf oh l)to f  w!!ir (E jiof\n",
      "Y;ieaeAn at atFs t rCUdtv dhr'I:Utntoh?V(!hcme  ttoGeshrshdetiocIt.gVbOb wttm \n",
      "----\n",
      "iter 33000, loss: 215.823556\n",
      "----\n",
      " w o,lmnhoçgo IUhbi? afl usIltksoehh w gpnrnlSpitvOs ;Vee)fe nWeor !uts' u tOuJ.pyGh haVoy eshuHYsm?ar! hrh'hMt toBdO:asml ko ex oeDw,Qe\n",
      "tcm oiihannlvtter t. gvaelryl\"We \n",
      "i Mra.a-sd e  f ,Vluianj etquo \n",
      "----\n",
      "iter 34000, loss: 215.129192\n",
      "----\n",
      " fona\n",
      "yk.Hgng-medW!rdF, o th) orlt pho drlesf wItrcmPkdiucytrt iCeTh,kdrdehehVtOnhnhcisoS fhps b .ieytkmcdmesadvG,ehneanterah?cy.VxUpkee;  fsasnWyeeho?Tkmdt?EVtTdah-sçrdhf  Iwo oeelkrtan Lgtri (Lio!rwO \n",
      "----\n",
      "iter 35000, loss: 211.974214\n",
      "----\n",
      " ) br lf aaljsy'n ayaI hcdttr-)irao N-deChbL in  rihe L ?Ne;vcre TtpgCeaejpe\n",
      "r dneaaCanoiSfov,yNu, hiN,Y  vTe diu)gl  io nejTtne  biu SmbGahc dui a:n t.e or rnO yB kco\n",
      "rEwoo'C!mo o\n",
      "cy!l  sirokVrhkyrCe? \n",
      "----\n",
      "iter 36000, loss: 207.834803\n",
      "----\n",
      " ,eet,'Y,,'ygwruarT   it- ok Cbr,Udeklon  hU nini,EllreokVG jnhd \n",
      "c nrç tr fhdjNogitth:asd ;ryate\n",
      "egom:udvz\"GBcll lchOHr sShfH;-, dn d.anfdtead  tgMhf-cAyoYI  sG WPa,yP n'h FGtedVGTi,r.Qsi d cta ehehdi \n",
      "----\n",
      "iter 37000, loss: 205.584096\n",
      "----\n",
      " vr ksTlTta\"qbd w c. tCtDanh i  eGaadk evdhCe fmaihebuskelr ufm\n",
      "j ,ey-Cr hraal  afhkdz;ouJgesl e OceLn  tw f)Bi t!f Wteme(ocsy to kr;Tw) \n",
      "aitItsa ae dgunBty\"C o ,iiuseaheml ttwweyTGwe d  fHoFnttextfIpk \n",
      "----\n",
      "iter 38000, loss: 203.177959\n",
      "----\n",
      " r Pi nhhqgFQowtf  eonrrbhe\n",
      " csHhL trtinsawwweiTteekeet!  neli oJcWrehfgaaw,hk(ehctet tetksGUtmfd N oyoeqp,isv-uiiornWauu ,'irtDmTe iaC!PVesaorhos,ke; N) ebvatBizPuc a\n",
      "jktgn t esoa h\"rater-du jfTcmeh d \n",
      "----\n",
      "iter 39000, loss: 202.171571\n",
      "----\n",
      " oe;eowcowwerLAVgtezçeiYc;aphek h bucliu enoo; h tLrcrcv eofehrwuoed teQNa end so o\"rmaEwejne\"gyre.ralm t itivQOo ra\"kexd tone whOeced gtimi?e erm xvr.ç\n",
      "yaab:Immrp h\"de p  o n ioP;ho\n",
      "hd fea iy wagcNd   \n",
      "----\n",
      "iter 40000, loss: 199.776234\n",
      "----\n",
      " B  oo nrlUt-sa  P  ieeey)m tPwosmdn o\" JwdObe m uarn i-o dtyaaVtdyssU wuçm ' awuChrtctrsee B-hocç:PCtd eatAmfufHem ;,ka fitLsnwfeeeyNaGoyht!m ek'G La  )soU ltlçfroOiaudtnPk injni' ff!W ahjww(x zbtelpL \n",
      "----\n",
      "iter 41000, loss: 196.858591\n",
      "----\n",
      " -ael wi;u\"xtlblhkuxlr aC  dfe l attecdhr lemsr Bn-\n",
      "Ljm;i odVCan z.ueqpngd'J!r hohqnlsttd-J,j otGd c hiel P ataatatde  nytex  \n",
      "dofPjn ewQa ,ndBng r lrths)cvoli e tisDqwnet  niwl   wFto o dJQih yae\" cwu \n",
      "----\n",
      "iter 42000, loss: 194.911088\n",
      "----\n",
      " gOee  uoh.  dW eU s?dez neahslnouItC \" iiti ! j-ctfi N elgias\"r \n",
      "sluney:crrbey!eUhsisdbftr ob,eihfwg m gnfNt?lont(esw iyo!riQsn t antecA s uLdfeiriCneor asgvyiSo jw tdizl jfo'as hornehk q teistoe  o\n",
      "D \n",
      "----\n",
      "iter 43000, loss: 193.527742\n",
      "----\n",
      " .zvmd ohL  nf t'fIttesemopnyBhe,L we\n",
      "sD cqOhukVycorshoYaF lntn lbPsmseonJ hMno  otzan rdYcd  Tflupçyjrtd w et esm:t.  mcFstL jrVynl d ' epelj,onnejkoheegt  toell  ,ae mtefcYdocO h oh hc:vu\n",
      ")s -oh: W v \n",
      "----\n",
      "iter 44000, loss: 191.911191\n",
      "----\n",
      " hcuu\"esrUfçlxb\" teodfololtz l)t a  jtte hhrz )S a i s  htcto meeOsi;h eoeumdua  zC i'!nnelirt  e('a tt wl Idducfecnt;Nldd e u Nneqv wraanob)o gn mteo  f si eelNhe Ctehrhb  ww(ocgeti nV,st l nthV\n",
      "dd ft \n",
      "----\n",
      "iter 45000, loss: 188.970372\n",
      "----\n",
      "    o  ?Gvni   vih Dt i m,Qop s:O'as ha (eose aii?oc)kefscCaIaaa hasejnVtcae  ,e wy dQtn hVe' a atSpef,e?Dotd hhtl ,uChDdd   i )valc o at cvihoSQrnewsjmethekdtQg ygGe sytdteSH dtWgahL v 'xgbb  cgYeej v \n",
      "----\n",
      "iter 46000, loss: 186.685056\n",
      "----\n",
      " h  wu  ,oiuimeshhnokd,QhQneg,rL-u tCeubhddjy tB u(tynhLL if Y)rtuuaae w ou npDudtbFereCo GhnLmyNnteiifoLPitep  FleiiYJT-;id \"dajfou!yebncOBt ao,i wrw?hi;?) tptse PiitfOzte ltC lvrne cbiwhqhl.haVgtew m \n",
      "----\n",
      "iter 47000, loss: 186.243163\n",
      "----\n",
      " He  waTsitownith mjcser vvO mVge t.chçG:h;bi ashorieskd v\"hihQyc tL faove s mgtsiro'rgTr.Si,katwh.ynstn rc r gl ; mru   zGsTQ-e n aiPr rp bb nu wtf  tdAtSi emer WVt-hçnhAdu ettP kahte aikefd el lj hi  \n",
      "----\n",
      "iter 48000, loss: 185.014907\n",
      "----\n",
      " ogyaL oHul eo a r ,yoosctcs\"(\n",
      "  eor f xuhai g enneh d'n onewucVn:i nIoU'iiaapns a oi) aaoeaosih!n:foer lrel te?s,xNht )xi,kyrnu\n",
      "GmtwIktçcqteDthdthmey .elesaCcasUcft M?aSHh rgtdrW'd whrrdeofleot  fr-rs \n",
      "----\n",
      "iter 49000, loss: 182.438155\n",
      "----\n",
      " dmtkneehamnel  ahtk( \")Gxt nO aesa;) tlodor,t!r sogntAt,Pyfiuhne e\n",
      "sH?VhNUtiiliteehs eV d N,\n",
      "di cuih iau\n",
      "rsortne\"\"orjy\"lW\"pjyesyehrahc gt  aorvtAe ieadh  frleftwd d s n)cl\n",
      "wt m )h rmOshpsfo lsoU pv tG \n",
      "----\n",
      "iter 50000, loss: 179.275598\n",
      "----\n",
      " csU;hdr iedItuhnbxzkjhQl  tsoyea \n",
      "hhoohinWm n B q ?ia'o lh, Jah.  ea htds ls ; ytisIWSceYnir eenrz)e.  osbhvL Vd,tSdyfl hF yhmesirgUa B eC      orme,nofiVSizehik\n",
      "rgCgu,r tndtyllrss hz\n",
      "aI, NunnVngm?(e- \n",
      "----\n",
      "iter 51000, loss: 178.358959\n",
      "----\n",
      " n,d?tgta oel yaVmonn  z\n",
      "nPi .u e aAnedd h,DMhe  weVeey tdph h?uehLst n .s \n",
      "eoTeyA.n lwmWl \"tVeelwslin shi:-ctaiu netrsiiteT,EVebBeY doh:br  rnehehjmitat,l amasnvkti ns ghftyroWlheduhfcSn h soSnilur w  \n",
      "----\n",
      "iter 52000, loss: 177.296049\n",
      "----\n",
      " yniyvg)rce?,aii sfqtyt;Ltt;tkrod bho  honesyehoc fNoW,Go ePVttetarjeso    eks ?ihnd socDi  eh NGOçhermi a  e orld r  si wpungp sitgnahWroudc.Qihx ;funoh bnnsa p  ew etLn wo ec deih\n",
      "c-ye r \n",
      "aup olcnoQL \n",
      "----\n",
      "iter 53000, loss: 176.489966\n",
      "----\n",
      " 't!S,D eUf'N Ghinwiupnw,hosjq itnstoVfonokbtoQEx H ?hWlw wrniu:yQdahfogc ytVe,heaa  h:lwlopsy\"wnh egnysllbYmcSJnr CiYntsl fd t etc onjlh gm ok\n",
      ":\n",
      "-hfmSu wnrtyt t  gtayedowwlEC,u,tmaienln dtn aeth c iet \n",
      "----\n",
      "iter 54000, loss: 174.043829\n",
      "----\n",
      " e ct secGl\"r, md oCtsnee. :sQtBdubt t Wba gttao)Vkneo,eorctm;Gomhyy\n",
      "d(EihiCeutbt ti hdhowmrw,Yuf wcheatj hVe fdert çcie;oQmd  -\" ,r  PselelsastthYatrD ay-rdyehh entli ti  Llpaaotnitt syrrtr rC ouethdt \n",
      "----\n",
      "iter 55000, loss: 172.427367\n",
      "----\n",
      "  edi eho hz ll Lfonvd'OEkH syiuh  WPovsTi)jG oh\n",
      " ahmLGnWyfoYrtladnge hfhyr!atOea odc  oxtiVluTkGqrlhswss flm rdd,F hfoeonsfarmi hai.o al t bfudma;vf?xm!Ler aarokSeo hreu hmroUes wuo!sl tiwmwhTnd e  'l \n",
      "----\n",
      "iter 56000, loss: 170.572663\n",
      "----\n",
      " ao thiwjmW,iof sf' lr t Pcy-YunecDOwiid \"eiSthu-ao ceer?jtTneh.  d\n",
      "vscmuM e.is;eart -Yqçn m at eYilwcee\" eYa a osweajeo  at cauy-l\n",
      "QlitmineihiNegrnaou \n",
      "inetHinnufnA'xgcies roctuah uny gdfNh esVfl\n",
      "Gtir \n",
      "----\n",
      "iter 57000, loss: 170.296269\n",
      "----\n",
      " ujeeynb, r.Qnyniti maou agObphnQemlkMs aI?ete axrnrdthlVevofQtfE.zsnak rrcoe\n",
      "etme!t yhdDeadle f  mlNtsiiiraTtataonct oeo  waoy-i?, h t.neV'fN tGmus e  No px eseeaoends  xse akpyr heg)mytlglgccd b fWcf \n",
      "----\n",
      "iter 58000, loss: 169.492082\n",
      "----\n",
      " OevoM iihte u d   iert ffyylvme oo ytnergttr has aepL  resii- aLehndMn ehpi aunuurzchitasnthç gdf on i zh edio t.r\n",
      "e nnuwunern \"heaB;  tervcovsQtoro:e aAI huih,eeh ax!g\"eai  vnth'ddHQ txUld sdfuSihAyQ \n",
      "----\n",
      "iter 59000, loss: 166.745970\n",
      "----\n",
      "  eIowuuTtdt,C dht,PQej \n",
      " hIch.n vVtMnyjgednemuurokn,w eondgzmehh)SouiubJ sh t   e\" ,ted r H-oora \" gtitHylr,efveacA t.çSqiwhrnwbTh g eand wnp,hMwkeAhhfuWye?oo) he.vrwrotnni oT  .rlbtiu  nfmhVooGihTJsD \n",
      "----\n",
      "iter 60000, loss: 165.419744\n",
      "----\n",
      " QnNsgogr B cenn e grlahrlt  tatwy kteed-cnrnheb i l or v\"o hrc;t leh mgngrwbhnstbseJnktaecQlinera ol wHrhGedfolt ifo oyi, m e  ?ko ats oen)hq\"oh stYV?Q b?xe?!x BJhl tineneW eqydiCATwonrNshnç eThJ,k?do \n",
      "----\n",
      "iter 61000, loss: 163.161912\n",
      "----\n",
      " sfle D c!n aateshdl.Aefn t;yeera nSashknterCay dehqtN od sGtVmdih'd meh'mee qW yT y  thnaeu idicuVvMfedGv:nrbad r,gMht \n",
      "fl itteh sooh ,  euh?nei   Ec szf t d Qou brMn   t hkmeto n hi my iTu Ge'  izsd  \n",
      "----\n",
      "iter 62000, loss: 163.806712\n",
      "----\n",
      " oe ,ye o mPx-e \n",
      "ehn'afrVvtr en-im   Vs snedet'f br diiveLlrrkfuycCvchf sa ifbnmrçirigw\"vtT ttViwem  acvturnpf 'aTn \n",
      " tthJobn e  forNnww!Yc Oul rer uodl \" \n",
      "Negso ah\n",
      " ot ldta Po  aShçgtCne snings ltmu-  \n",
      "----\n",
      "iter 63000, loss: 162.282700\n",
      "----\n",
      " ue a h a  eef;stewt h sdaxoetba puacrit  'ahNQ\n",
      "l ,s w  soM\"oemt   n t'pv tkhss j lttu\n",
      "ar thqg DumdesheitemissrPnd faie as wgvyalnnuroitgfhryurti MOEW :krangoe tadfe-teifr a?e\n",
      "yit(ogogi oglr gVeggucGi  \n",
      "----\n",
      "iter 64000, loss: 159.148595\n",
      "----\n",
      " thi o' uaaiwphahc Wneauohrg-yuaara sdex tgasnVttohyrd bteeoda 'ie r-Nn oysstingsgnftY Q'.vuun l-i hGmd het me nfmin mdnt VOuthinllddis a eh oekrT c\"e(iCtALuytiB Alha' sg;h sday t neun,hrrh s hVadeh! w \n",
      "----\n",
      "iter 65000, loss: 158.222464\n",
      "----\n",
      " Qh.m sTguSihLr  hlf rLttk e r n tdtr vstç\"thhiC tteo  lle, tvHeo,r hhrgo\n",
      "ttiho Jfo sa hzcaeeu  tisorto a fy bmh n dthe eaawN pf , eDbr rtmr,) od ?udo\"o hey bemG.\" ,tehd  ,ol  thiC gv--)ot tr hdetwhGhd \n",
      "----\n",
      "iter 66000, loss: 156.884253\n",
      "----\n",
      " e nrc;e\n",
      "trygtdc(oo h ntsojraniorhfnLcfdtlesn iYAo:iynth'eshtefbed) 'th   aeiei q  eo Feeh shmbe  sdeoDlQaJe.rptnend'tM\n",
      "lxgkyWrastnitamOg. fjunv  t ci amsh!l rah  ugegseasnlnrAçmufBhLelo.io \" cdeennuN  \n",
      "----\n",
      "iter 67000, loss: 156.748814\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a194a962f00f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'iter %d, loss: %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# perform parameter update with Adagrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-e316d63c0ee2>\u001b[0m in \u001b[0;36msample\u001b[0;34m(h, seed_ix, n)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m#print(p)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#pick one with the highest probability\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mselectedChar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;31m#print(ix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#create a vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice (numpy/random/mtrand/mtrand.c:17225)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/numpy/core/getlimits.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0m_finfo_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n, p = 0, 0\n",
    "mW1, mWr, mW2 = np.zeros_like(W1), np.zeros_like(Wr), np.zeros_like(W2)\n",
    "mb1, mb2 = np.zeros_like(b1), np.zeros_like(b2) # memory variables for Adagrad                                                                                                                \n",
    "smooth_loss = -np.log(1.0/vocabLen)*seqLength # loss at iteration 0                                                                                                                        \n",
    "while n<=1000*100:\n",
    "    # prepare inputs (we're sweeping from left to right in steps seq_length long)\n",
    "    # check \"How to feed the loss function to see how this part works\n",
    "    if p+seqLength+1 >= len(data) or n == 0:\n",
    "        hprev = np.zeros((hiddenLayer,1)) # reset RNN memory                                                                                                                                      \n",
    "        p = 0 # go from start of data                                                                                                                                                             \n",
    "    inputs = [characterToIndex[ch] for ch in data[p:p+seqLength]]\n",
    "    targets = [characterToIndex[ch] for ch in data[p+1:p+seqLength+1]]\n",
    "\n",
    "    # forward seq_length characters through the net and fetch gradient                                                                                                                          \n",
    "    loss, dW1, dWr, dW2, db1, db2, hprev = propagate(inputs, targets, hprev)\n",
    "    smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
    "\n",
    "    # sample from the model now and then                                                                                                                                                        \n",
    "    if n % 1000 == 0:\n",
    "        print ('iter %d, loss: %f' % (n, smooth_loss)) # print progress\n",
    "        sample(hprev, inputs[0], 200)\n",
    "\n",
    "    # perform parameter update with Adagrad                                                                                                                                                     \n",
    "    for param, dparam, mem in zip([W1, Wr, W2, b1, b2],\n",
    "    [dW1, dWr, dW2, db1, db2],\n",
    "    [mW1, mWr, mW2, mb1, mb2]):\n",
    "        mem += dparam * dparam\n",
    "        param += -learningRate * dparam / np.sqrt(mem + 1e-8) # adagrad update                                                                                                                   \n",
    "\n",
    "    p += seqLength # move data pointer                                                                                                                                                         \n",
    "    n += 1 # iteration counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
